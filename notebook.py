# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wDjyFpcd05cqBSjKlKVvpuhbmcx59tpz

# Proyek Akhir : Membuat Model Sistem Rekomendasi

Nama : Alivia Vinca Kustaryono

Cohort ID : MC006D5X2041

Email : mc006d5x2041@student.devacademy.id

# Data Loading

## Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from zipfile import ZipFile

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

import warnings
warnings.filterwarnings('ignore')

"""## Upload dan ekstrak dataset"""

# Import module yang disediakan google colab untuk kebutuhan upload file
from google.colab import files
files.upload()

# Download kaggle dataset dan unzip file
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d CooperUnion/anime-recommendations-database

!unzip anime-recommendations-database.zip

"""## Load Dataset"""

# Baca dataset CSV
anime = pd.read_csv('anime.csv')
rating = pd.read_csv('rating.csv')

anime.head()

rating.head()

"""# Exploratory Data Analysis (EDA)

## Struktur Data
"""

# Cek informasi dataset
anime.info()
print('-----------------------------------------------------------')
rating.info()

# Cek jumlah baris dan kolom
print(anime.shape)
print('-----------------------------------------------------------')
print(rating.shape)

# Statistik deskriptif
anime.describe()

rating.describe()

# Cek data kosong
anime.isnull().sum()

rating.isnull().sum()

# Cek jumlah data duplikat
anime.duplicated().sum()

rating.duplicated().sum()

"""## Visualisasi Genre dan Tipe Anime"""

# Menghitung genre anime
genres = anime['genre'].dropna().str.cat(sep=',').split(',')
genres = pd.Series(genres).value_counts()
genres.head(20)

# Visualisasi genre anime
plt.figure(figsize=(12, 6))
sns.barplot(
    x=genres.head(10).index,
    y=genres.head(10).values,
    palette=sns.color_palette("coolwarm", n_colors=10)
)
plt.title('Top 10 Genre Anime')
plt.xlabel('Genre')
plt.ylabel('Jumlah')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Menghitung tipe anime
tipe_anime = anime['type'].value_counts()
tipe_anime

# Visualisasi tipe anime
plt.figure(figsize=(12, 6))
sns.barplot(
    x=tipe_anime.head().index,
    y=tipe_anime.head().values,
    palette=sns.color_palette("coolwarm", n_colors=10)
)
plt.title('Jenis-Jenis Anime Berdasarkan Tipe')
plt.xlabel('Tipe Anime')
plt.ylabel('Jumlah')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""# Data Preprocessing

1. Sampling 50000 Rating
"""

# Sampling 50000 Rating
rating_sample = rating.sample(n=50000, random_state=42)

rating_sample.info()

rating_sample.head()

"""2. Membersihkan kolom kosong pada dataset anime"""

# Membersihkan kolom kosong

# Isi missing value pada kolom 'genre' dengan 'Unknown'
anime['genre'] = anime['genre'].fillna('Unknown')

# Isi missing value pada kolom 'type' dengan 'Unknown'
anime['type'] = anime['type'].fillna('Unknown')

# Isi missing value pada kolom 'rating' dengan 0.00
anime['rating'] = anime['rating'].fillna(0.00)

anime.isnull().sum()

"""3. Membersihkan nama anime dari karakter non-alfabetnumerik"""

# Membersihkan Nama Anime
anime['name'] = anime['name'].str.replace(r'[^a-zA-Z0-9\s]', '', regex=True)

anime.head()

"""4. Standarisasi genre anime menjadi hanya satu genre pertamanya"""

# Standarisasi genre anime
anime['genre'] = anime['genre'].apply(lambda x: x.split(',')[0].strip())

general_genre = anime.groupby('name')['genre'].agg(lambda x: x.mode().iloc[0]).reset_index()

anime = anime.drop(columns='genre').merge(general_genre, on='name').rename(columns={'genre': 'genre'})

anime.head()

"""# Model Development Content Based Filtering"""

# Menampilkan data kolom nama dan genre
anime[['name','genre']].head()

"""## TF-IDF Vectorizer"""

# Inisialisasi TfidfVectorizer
tfidf = TfidfVectorizer()

# Melakukan perhitungan idf pada data genre
tfidf.fit(anime['genre'])

# Mapping array dari fitur index integer ke fitur nama
tfidf.get_feature_names_out()

# Transformasi genre ke bentuk matriks TF-IDF
tfidf_matrix = tfidf.fit_transform(anime['genre'])

# Melihat ukuran matriks TF-IDF
print("Ukuran Matrix TF-IDF:", tfidf_matrix.shape)

# Mengubah vektor TF-IDF dalam bentuk matriks
tfidf_matrix.todense()

# Membuat dataframe untuk melihat matrix TF-IDF
pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf.get_feature_names_out(),
    index=anime['name']
)

"""### Cosine Similarity"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe cosine similiarity antar anime
cosine_sim_df = pd.DataFrame(cosine_sim, index=anime['name'], columns=anime['name'])

# Menampilkan ukuran matriks cosine similiarity
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap anime
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Mendapatkan Rekomendasi"""

def anime_recommendations(anime_name, similarity_data=cosine_sim_df, items=anime[['name', 'genre']], k=5):
    """
    Rekomendasi Anime berdasarkan kemiripan dataframe

    Parameter:
    ---
    nama_anime : tipe data string (str)
                 Nama Anime (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetris, dengan anime sebagai indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---

    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,anime_name].to_numpy().argpartition(range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_movie agar nama movie yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(anime_name, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

# Cek data anime
anime[anime['name'].eq('Sword Art Online')]

# Mendapatkan rekomendasi anime mirip dengan anime yang di panggil
anime_recommendations('Sword Art Online')

"""# Model Development dengan Collaborative Filtering"""

# Menampilkan data rating yang sudah di sampling
rating_sample.head()

"""### Data Preparation"""

#Filter rating

# Hapus rating yang tidak valid (âˆ’1)
rating_sample = rating_sample[rating_sample['rating'] != -1]

# Mengambil anime dari dataset anime
rating_sample = rating_sample[rating_sample['anime_id'].isin(anime['anime_id'])]

# Filter user dengan minimal 5 rating
user_counts = rating_sample['user_id'].value_counts()
active_users = user_counts[user_counts >= 5].index
rating_sample = rating_sample[rating_sample['user_id'].isin(active_users)]

# Reset index setelah filter
rating_sample.reset_index(drop=True, inplace=True)

# Info data setelah preprocessing
print("Shape anime:", anime.shape)
print("Shape rating_sample:", rating_sample.shape)
print("Sample rating_sample:")
print(rating_sample.head())

# Encode user_id dan anime_id menjadi index numerik
user_ids = rating_sample['user_id'].unique().tolist()
anime_ids = rating_sample['anime_id'].unique().tolist()

user2user_encoded = {x: i for i, x in enumerate(user_ids)}
anime2anime_encoded = {x: i for i, x in enumerate(anime_ids)}

rating_sample['user'] = rating_sample['user_id'].map(user2user_encoded)
rating_sample['anime'] = rating_sample['anime_id'].map(anime2anime_encoded)

# Tentukan jumlah user dan anime
num_users = len(user2user_encoded)
num_anime = len(anime2anime_encoded)

print(f'Jumlah users: {num_users}, Jumlah anime: {num_anime}')

"""### Membagi Data untuk Training dan Validasi"""

# Split data train dan validasi

# Membuat variabel x untuk mencocokkan data user dan resto menjadi satu value
x = rating_sample[['user', 'anime']].values

# Membuat variabel y untuk membuat rating dari hasil
y = rating_sample['rating'].values

print(f"Jumlah rating akhir: {rating_sample.shape[0]}")

# Membagi menjadi 80% data train dan 20% data validasi
x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)

print(f"x_train shape: {x_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"x_val shape: {x_val.shape}")
print(f"y_val shape: {y_val.shape}")
print(x, y)

"""### Proses Training"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_anime, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_anime = num_anime
    self.embedding_size = embedding_size

    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.anime_embedding = layers.Embedding( # layer embeddings movie
        num_anime,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.anime_bias = layers.Embedding(num_anime, 1) # layer embedding movie bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    anime_vector = self.anime_embedding(inputs[:, 1]) # memanggil layer embedding 3
    anime_bias = self.anime_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_anime = tf.tensordot(user_vector, anime_vector, 2)

    x = dot_user_anime + user_bias + anime_bias
    # Menggunakan sigmoid hanya jika output rating 0-1.
    # Jika rating 1-10, jangan gunakan sigmoid dan pertimbangkan Mean Squared Error sebagai loss.
    return x

model = RecommenderNet(num_users, num_anime, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.MeanSquaredError(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""### Training model"""

# Training Training Model
print("\nMemulai proses training model...")
history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=32, # Ukuran batch yang lebih kecil dari tf.data.Dataset batch (1024)
                    # karena ini adalah batch untuk proses training di Keras fit
    epochs=50,      # Jumlah epoch, sesuaikan sesuai kebutuhan dan kinerja
    validation_data=(x_val, y_val),
    verbose=1       # Menampilkan progress training
)
print("\nProses training selesai.")

# Hasil Evaluasi dengan MSE & RMSE
results = model.evaluate(x_val, y_val, verbose=1)

print("\nHasil Evaluasi pada Data Validasi:")
print(f"Loss (MSE): {results[0]:.4f}")
print(f"RMSE: {results[1]:.4f}")

# Visualisasi metrik
def plot_rmse(history):
    plt.plot(history.history['root_mean_squared_error'])
    plt.plot(history.history['val_root_mean_squared_error'])
    plt.title('Model RMSE')
    plt.ylabel('RMSE')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Validation'], loc='upper left')
    plt.grid(True)
    plt.show()
plot_rmse(history)

"""### Mendapatkan Rekomendasi"""

anime_df = anime.copy()
rating_df = rating_sample.copy()

# Mengambil sample user
userId = rating_sample.user_id.sample(1).iloc[0]
anime_watched_by_user = rating_sample[rating_sample.user_id == userId]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
anime_not_watched_ids = anime_df[~anime_df['anime_id'].isin(anime_watched_by_user.anime_id.values)]['anime_id']
encoded_user_id = user2user_encoded[userId]
encoded_anime_not_watched = [anime2anime_encoded.get(anime_id) for anime_id in anime_not_watched_ids if anime_id in anime2anime_encoded]

user_anime_array = np.hstack((
    np.array([[encoded_user_id]] * len(encoded_anime_not_watched)),
    np.array(encoded_anime_not_watched).reshape(-1, 1)
))

ratings = model.predict(user_anime_array).flatten()

# Ambil indeks dengan prediksi rating tertinggi
top_ratings_indices = ratings.argsort()[-10:][::-1]

# Karena kita pakai ID asli, ambil langsung dari anime_not_watched
recommended_anime_ids = [anime_not_watched_ids.iloc[x] for x in top_ratings_indices]

print('Showing recommendations for user:', userId)
print('===' * 9)
print('Anime with high ratings from user')
print('----' * 8)

# Ambil 5 anime dengan rating tertinggi dari user tersebut
top_anime_user_ids = (
    anime_watched_by_user.sort_values(
        by='rating',
        ascending=False
    )
    .head(5)
    .anime_id.values
)

# Tampilkan anime yang sudah pernah ditonton dan disukai user
anime_df_rows = anime_df[anime_df['anime_id'].isin(top_anime_user_ids)]
for row in anime_df_rows.itertuples():
    print(row.name, ':', row.genre)

print('----' * 8)
print('Top 10 anime recommendation')
print('----' * 8)

# Tampilkan anime hasil rekomendasi model
recommended_anime = anime_df[anime_df['anime_id'].isin(recommended_anime_ids)]
for row in recommended_anime.itertuples():
    print(row.name, ':', row.genre)